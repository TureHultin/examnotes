{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0960f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b217ac",
   "metadata": {},
   "source": [
    "PROBLEM 1: Data analysis using markov chians \n",
    "\n",
    "In this problem, you will empirically analyze a Markov chain \n",
    "with a finite state space. Transition probabilities are unknown.\n",
    "\n",
    "The state space is:\n",
    "    S = {0, 1, 2, 3}\n",
    "\n",
    "You are given the data for the observed X_t for t  = 0..19\n",
    "\n",
    "Tasks:\n",
    "1. Estimate the transition matrix P from the observed transitions.\n",
    "2. Verify that the estimated matrix is a probability transition matrix.\n",
    "3. Compute the stationary distribution pi of the chain.\n",
    "4. Simulate the chain using the estimated transition matrix\n",
    "5. Compute the expected hitting times via\n",
    "\n",
    "   (a) Simulation\n",
    "\n",
    "   (b) Solving linear equations (analytical hitting times). \n",
    "\n",
    "Compare the estimates and interpret the results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a471499",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# state space\n",
    "S = [0, 1, 2, 3]\n",
    "N_states = len(S)\n",
    "\n",
    "# Observed transitions: each row is (current_state, next_state)\n",
    "X_t = np.array([\n",
    "    [0, 1],\n",
    "    [1, 2],\n",
    "    [2, 3],\n",
    "    [3, 0],\n",
    "    [0, 1],\n",
    "    [1, 1],\n",
    "    [1, 2],\n",
    "    [2, 2],\n",
    "    [2, 3],\n",
    "    [3, 3],\n",
    "    [3, 0],\n",
    "    [0, 2],\n",
    "    [2, 1],\n",
    "    [1, 3],\n",
    "    [3, 1],\n",
    "    [1, 0],\n",
    "    [0, 0],\n",
    "    [0, 1],\n",
    "    [1, 2],\n",
    "    [2, 0],\n",
    "], dtype=int)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c22d60",
   "metadata": {},
   "source": [
    "Below are methods that you need to complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b339dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1\n",
    "def comp_transition_matrix(transitions, n_states):\n",
    "    \"\"\"\n",
    "    Estimate the transition matrix P from observed transitions.\n",
    "\n",
    "    Args:\n",
    "        transitions: array of shape (n_samples, 2)\n",
    "        n_states: number of states\n",
    "\n",
    "    Returns:\n",
    "        P_hat: estimated transition matrix\n",
    "    \"\"\"\n",
    "    P_hat = np.zeros((n_states, n_states))\n",
    "    \n",
    "    # implement P_hat\n",
    "    for n in range(n_states):\n",
    "        counter0 = 0\n",
    "        counter1 = 0\n",
    "        counter2 = 0\n",
    "        counter3 = 0\n",
    "        for j in transitions:\n",
    "            if(j[0]==n):\n",
    "                if(j[1]==0):\n",
    "                    counter0+=1\n",
    "                if(j[1]==1):\n",
    "                    counter1+=1\n",
    "                if(j[1]==2):\n",
    "                    counter2+=1\n",
    "                if(j[1]==3):\n",
    "                    counter3+=1\n",
    "        tot = counter0+counter1+counter2+counter3\n",
    "        P_hat[n][0]=counter0/tot\n",
    "        P_hat[n][1]=counter1/tot\n",
    "        P_hat[n][2]=counter2/tot\n",
    "        P_hat[n][3]=counter3/tot\n",
    "\n",
    "    return P_hat\n",
    "\n",
    "\n",
    "#  1.2\n",
    "def is_transition_matrix(P):\n",
    "    \"\"\"\n",
    "    Check if P is a transition matrix.\n",
    "    \"\"\"\n",
    "    for row in P:\n",
    "        sum=0\n",
    "        for n in row:\n",
    "            sum+=n\n",
    "        if(sum<0.9999 or sum>1.0001):\n",
    "            print(sum)\n",
    "            return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "\n",
    "# 1.3\n",
    "def stationary_distribution(P): \n",
    "    \"\"\"\n",
    "    Compute stationary distribution\n",
    "    \"\"\"\n",
    "\n",
    "    P = P.transpose()\n",
    "    eigvals, eigvecs = np.linalg.eig(P)\n",
    "\n",
    "    pi = np.zeros(len(eigvals))\n",
    "    for y in range(len(eigvals)):\n",
    "        if np.isclose(eigvals[y], 1):\n",
    "            pi = eigvecs[:, y].real\n",
    "            break\n",
    "\n",
    "    tot=0\n",
    "    for i in pi:\n",
    "        tot+=i\n",
    "    norm = np.zeros(len(pi))\n",
    "    for y in range(len(pi)):\n",
    "        norm[y] = pi[y]/tot\n",
    "    \n",
    "    \n",
    "    # Here you implement the method for computing pi. Remember that we did it during lessons - and there are at least 2 ways of computing pi. You can choose either of them\n",
    "    print(pi)\n",
    "    print(norm)\n",
    "    return norm\n",
    "\n",
    "\n",
    "\n",
    "def simulate_chain(P, start_state, n_steps):\n",
    "    \"\"\"\n",
    "    Simulate a Markov chain trajectory with a fixed random seed.\n",
    "\n",
    "    Returns: array of visited states of length n_steps + 1\n",
    "    \"\"\"\n",
    "    seed = 1234 # don't change that\n",
    "    \n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    path = np.zeros(n_steps + 1, dtype=int)\n",
    "    path[0] = start_state\n",
    "\n",
    "    for n in range(n_steps):\n",
    "        path[n+1] = rng.choice([0,1,2,3], p=P[path[n]])\n",
    "\n",
    "    #  sample next states using rng.choice\n",
    "\n",
    "    return path\n",
    "\n",
    "\n",
    "\n",
    "def hitting_times_sim(P, start_state, n_sim=10_000):\n",
    "    N_states = P.shape[0]\n",
    "    est = np.zeros(N_states)\n",
    "\n",
    "    rng = np.random.default_rng(1234)\n",
    "    states = np.arange(N_states)\n",
    "\n",
    "    for j in range(N_states):\n",
    "        times = []\n",
    "\n",
    "        for _ in range(n_sim):\n",
    "            current = start_state\n",
    "            t = 1  # convention: hitting time of start_state is 1\n",
    "\n",
    "            while current != j:\n",
    "                current = rng.choice(states, p=P[current])\n",
    "                t += 1\n",
    "\n",
    "            times.append(t)\n",
    "\n",
    "        est[j] = np.mean(times)\n",
    "\n",
    "    return est\n",
    "\n",
    "\n",
    "\n",
    "def theoretical_hitting_times(P, start_state):\n",
    "    N_states = P.shape[0]\n",
    "    hit_theor = np.zeros(N_states)\n",
    "\n",
    "    for target in range(N_states):\n",
    "        if target == start_state:\n",
    "            hit_theor[target] = 1 # Matches your simulation convention\n",
    "            continue\n",
    "            \n",
    "        # Solve (I - P')h = 1, where P' is P with the target state row modified\n",
    "        A = np.eye(N_states) - P\n",
    "        b = np.ones(N_states)\n",
    "        \n",
    "        # Boundary condition: Expected time to hit target from target is 0\n",
    "        # In your simulation, you use a convention where start is 1, \n",
    "        # so we solve for 0 and add 1 at the end if necessary.\n",
    "        A[target, :] = 0\n",
    "        A[target, target] = 1\n",
    "        b[target] = 0\n",
    "        \n",
    "        h = np.linalg.solve(A, b)\n",
    "        # Add 1 to match your simulation's 't = 1' starting convention\n",
    "        hit_theor[target] = h[start_state] + 1 \n",
    "\n",
    "    return hit_theor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f250cf14",
   "metadata": {},
   "source": [
    "When you are done, run the following cell (no need to implement anything else)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e017a69e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Problem 1: Markov chain estimation + hitting times ===\n",
      "Estimated P_hat:\n",
      " [[0.2   0.6   0.2   0.   ]\n",
      " [0.167 0.167 0.5   0.167]\n",
      " [0.2   0.2   0.2   0.4  ]\n",
      " [0.5   0.25  0.    0.25 ]]\n",
      "Is valid transition matrix? True\n",
      "[-0.49507377 -0.59408853 -0.49507377 -0.39605902]\n",
      "[0.25 0.3  0.25 0.2 ]\n",
      "\n",
      "Comparison table:\n",
      "    target_state  MC_estimate  theoretical  abs_diff\n",
      "0             0       1.0000     1.000000  0.000000\n",
      "1             1       3.0154     3.024390  0.008990\n",
      "2             2       4.2912     4.317073  0.025873\n",
      "3             3       6.6374     6.682927  0.045527\n"
     ]
    }
   ],
   "source": [
    "def problem1_main():\n",
    "    print(\"\\n=== Problem 1: Markov chain estimation + hitting times ===\")\n",
    "\n",
    "    # 1) Estimate P\n",
    "    P_hat = comp_transition_matrix(X_t, N_states)\n",
    "    print(\"Estimated P_hat:\\n\", np.round(P_hat, 3))\n",
    "\n",
    "    # 2) Validate\n",
    "    print(\"Is valid transition matrix?\", is_transition_matrix(P_hat))\n",
    "\n",
    "    stationary_distribution(P_hat)\n",
    "\n",
    "    # 3) Expected steps from given start state to all states\n",
    "    start_state = 0\n",
    "\n",
    "    # simulation\n",
    "    mc = hitting_times_sim(P_hat, start_state=start_state, n_sim=5000)\n",
    "\n",
    "    # Theory (linear system)\n",
    "    th = theoretical_hitting_times(P_hat, start_state=start_state)\n",
    "\n",
    "    # 4) Compare\n",
    "    df = pd.DataFrame({\n",
    "        \"target_state\": np.arange(N_states),\n",
    "        \"MC_estimate\": mc,\n",
    "        \"theoretical\": th,\n",
    "        \"abs_diff\": np.abs(mc - th),\n",
    "    })\n",
    "    print(\"\\nComparison table:\\n\", df)\n",
    "\n",
    "problem1_main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a45403",
   "metadata": {},
   "source": [
    "PROBLEM 2: Cost-Sensitive Classification\n",
    "\n",
    "You are given a binary classification problem for fraud detection.\n",
    "\n",
    "Class labels:\n",
    "\n",
    "    y = 1 => fraud\n",
    "\n",
    "    y = 0 => ok\n",
    "\n",
    "\n",
    "\n",
    "The costs of classification outcomes are:\n",
    "    TP = 0, TN = 0, FP = 100, FN = 500\n",
    "\n",
    "Tasks:\n",
    "1. Train an SVM classifier.\n",
    "2. Compute classification costs at a fixed threshold (0.5).\n",
    "3. Evaluate total cost for multiple probability thresholds.\n",
    "4. Find the threshold that minimizes total cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc6371ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.250243</td>\n",
       "      <td>-0.863902</td>\n",
       "      <td>-0.307019</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.380736</td>\n",
       "      <td>0.018756</td>\n",
       "      <td>-0.559577</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.126431</td>\n",
       "      <td>2.055912</td>\n",
       "      <td>0.973126</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.806991</td>\n",
       "      <td>2.104160</td>\n",
       "      <td>-0.211368</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.059649</td>\n",
       "      <td>0.652374</td>\n",
       "      <td>-0.437259</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         x1        x2        x3  fraud\n",
       "0 -0.250243 -0.863902 -0.307019      0\n",
       "1 -0.380736  0.018756 -0.559577      0\n",
       "2  1.126431  2.055912  0.973126      1\n",
       "3  0.806991  2.104160 -0.211368      1\n",
       "4  0.059649  0.652374 -0.437259      0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "costs = {\"TP\": 0, \"TN\": 0, \"FP\": 100, \"FN\": 500}\n",
    "\n",
    "\n",
    "def generate_fraud_table(seed=0, n=3000, fraud_rate=0.05):\n",
    "    \"\"\"\n",
    "    Generate a simple fraud dataset as a single table. The table contains:\n",
    "        - numerical features: x1, x2, x3\n",
    "        - binary target column: fraud (1 = fraud, 0 = legitimate)\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    # Target variable\n",
    "    fraud = (rng.random(n) < fraud_rate).astype(int)\n",
    "\n",
    "    # Features\n",
    "    x1 = rng.normal(0, 1, size=n)\n",
    "    x2 = rng.normal(0, 1, size=n)\n",
    "    x3 = rng.normal(0, 1, size=n)\n",
    "\n",
    "    #  fraud cases are shifted\n",
    "    x1[fraud == 1] += 2.0\n",
    "    x2[fraud == 1] += 1.0\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        \"x1\": x1,\n",
    "        \"x2\": x2,\n",
    "        \"x3\": x3,\n",
    "        \"fraud\": fraud,\n",
    "    })\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "fraud_data = generate_fraud_table()\n",
    "\n",
    "fraud_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031231e8",
   "metadata": {},
   "source": [
    "Fill in the methods in the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d03aae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "costs = {\"TP\": 0, \"TN\": 0, \"FP\": 100, \"FN\": 500}\n",
    "\n",
    "def train_test_split_table(df):\n",
    "    # Fix: Use double brackets for list of column names\n",
    "    X = df[[\"x1\", \"x2\", \"x3\"]]\n",
    "    y = df[\"fraud\"]\n",
    "    # Added random_state for consistency\n",
    "    return train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "def fit_linear_svm(fraud_data):\n",
    "    clf = LinearSVC(C=1.0, max_iter=10_000, random_state=0)\n",
    "    X_train, X_test, y_train, y_test = train_test_split_table(fraud_data)\n",
    "    \n",
    "    # Fix: Fit first, then predict\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    return y_pred, y_test, clf, X_test\n",
    "\n",
    "def confusion_counts(y_true, y_pred):\n",
    "    # Fix: Reset to numpy arrays to ensure indexing works\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    \n",
    "    TP, TN, FP, FN = 0, 0, 0, 0 \n",
    "    \n",
    "    for n in range(len(y_true)):\n",
    "        if y_true[n] == 1 and y_pred[n] == 1:\n",
    "            TP += 1\n",
    "        elif y_true[n] == 1 and y_pred[n] == 0:\n",
    "            FN += 1\n",
    "        elif y_true[n] == 0 and y_pred[n] == 0:\n",
    "            TN += 1\n",
    "        elif y_true[n] == 0 and y_pred[n] == 1:\n",
    "            FP += 1\n",
    "    \n",
    "    return {\"TP\": TP, \"TN\": TN, \"FP\": FP, \"FN\": FN}\n",
    "\n",
    "def total_cost(counts):\n",
    "    # Fix: Direct dictionary key multiplication\n",
    "    total = (counts[\"TP\"] * costs[\"TP\"] + \n",
    "             counts[\"TN\"] * costs[\"TN\"] + \n",
    "             counts[\"FP\"] * costs[\"FP\"] + \n",
    "             counts[\"FN\"] * costs[\"FN\"])\n",
    "    return total\n",
    "\n",
    "def sweep_thresholds(y_true, thresholds, X, clf):\n",
    "    results = []\n",
    "    # decision_function returns the distance to the separating hyperplane\n",
    "    y_scores = clf.decision_function(X)\n",
    "\n",
    "    for t in thresholds:\n",
    "        y_pred = (y_scores >= t).astype(int)\n",
    "        counts = confusion_counts(y_true, y_pred)\n",
    "        cost = total_cost(counts)\n",
    "\n",
    "        results.append({\n",
    "            \"threshold\": t,\n",
    "            \"TP\": counts[\"TP\"],\n",
    "            \"TN\": counts[\"TN\"],\n",
    "            \"FP\": counts[\"FP\"],\n",
    "            \"FN\": counts[\"FN\"],\n",
    "            \"total_cost\": cost,\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12c44a4",
   "metadata": {},
   "source": [
    "When you are done, run the following cell (no need to implement anything else)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4235863e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold sweep results (first 5 rows):\n",
      "    threshold  TP   TN   FP  FN  total_cost\n",
      "0        -2.0  39  182  379   0       37900\n",
      "1        -1.8  39  259  302   0       30200\n",
      "2        -1.6  39  306  255   0       25500\n",
      "3        -1.4  39  376  185   0       18500\n",
      "4        -1.2  39  422  139   0       13900\n",
      "5        -1.0  39  472   89   0        8900\n",
      "6        -0.8  36  506   55   3        7000\n",
      "7        -0.6  32  527   34   7        6900\n",
      "8        -0.4  31  539   22   8        6200\n",
      "9        -0.2  26  551   10  13        7500\n",
      "10        0.0  23  557    4  16        8400\n",
      "11        0.2  21  560    1  18        9100\n",
      "12        0.4  14  560    1  25       12600\n",
      "13        0.6   9  561    0  30       15000\n",
      "14        0.8   6  561    0  33       16500\n",
      "15        1.0   2  561    0  37       18500\n",
      "16        1.2   1  561    0  38       19000\n",
      "17        1.4   1  561    0  38       19000\n",
      "18        1.6   0  561    0  39       19500\n",
      "19        1.8   0  561    0  39       19500\n",
      "20        2.0   0  561    0  39       19500\n",
      "\n",
      "--- Optimal Result ---\n",
      "threshold       -0.4\n",
      "TP              31.0\n",
      "TN             539.0\n",
      "FP              22.0\n",
      "FN               8.0\n",
      "total_cost    6200.0\n",
      "Name: 8, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Global cost configuration\n",
    "costs = {\"TP\": 0, \"TN\": 0, \"FP\": 100, \"FN\": 500}\n",
    "\n",
    "def generate_fraud_table(seed=0, n=3000, fraud_rate=0.05):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    fraud = (rng.random(n) < fraud_rate).astype(int)\n",
    "    x1 = rng.normal(0, 1, size=n)\n",
    "    x2 = rng.normal(0, 1, size=n)\n",
    "    x3 = rng.normal(0, 1, size=n)\n",
    "    x1[fraud == 1] += 2.0\n",
    "    x2[fraud == 1] += 1.0\n",
    "    return pd.DataFrame({\"x1\": x1, \"x2\": x2, \"x3\": x3, \"fraud\": fraud})\n",
    "\n",
    "def train_test_split_table(df):\n",
    "    # Use double brackets for list of columns\n",
    "    X = df[[\"x1\", \"x2\", \"x3\"]]\n",
    "    y = df[\"fraud\"]\n",
    "    return train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "def fit_linear_svm(df):\n",
    "    X_train, X_test, y_train, y_test = train_test_split_table(df)\n",
    "    clf = LinearSVC(C=1.0, max_iter=10_000, random_state=0)\n",
    "    clf.fit(X_train, y_train)\n",
    "    return clf  # Return the fitted model object\n",
    "\n",
    "def confusion_counts(y_true, y_pred):\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    TP = np.sum((y_true == 1) & (y_pred == 1))\n",
    "    TN = np.sum((y_true == 0) & (y_pred == 0))\n",
    "    FP = np.sum((y_true == 0) & (y_pred == 1))\n",
    "    FN = np.sum((y_true == 1) & (y_pred == 0))\n",
    "    return {\"TP\": TP, \"TN\": TN, \"FP\": FP, \"FN\": FN}\n",
    "\n",
    "def total_cost(counts):\n",
    "    return (counts[\"TP\"] * costs[\"TP\"] + \n",
    "            counts[\"TN\"] * costs[\"TN\"] + \n",
    "            counts[\"FP\"] * costs[\"FP\"] + \n",
    "            counts[\"FN\"] * costs[\"FN\"])\n",
    "\n",
    "def sweep_thresholds(y_true, thresholds, X, clf):\n",
    "    results = []\n",
    "    # decision_function returns raw distance from the hyperplane\n",
    "    y_scores = clf.decision_function(X)\n",
    "\n",
    "    for t in thresholds:\n",
    "        y_pred = (y_scores >= t).astype(int)\n",
    "        counts = confusion_counts(y_true, y_pred)\n",
    "        cost = total_cost(counts)\n",
    "\n",
    "        results.append({\n",
    "            \"threshold\": t,\n",
    "            \"TP\": counts[\"TP\"],\n",
    "            \"TN\": counts[\"TN\"],\n",
    "            \"FP\": counts[\"FP\"],\n",
    "            \"FN\": counts[\"FN\"],\n",
    "            \"total_cost\": cost,\n",
    "        })\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "def main():\n",
    "    df = generate_fraud_table()\n",
    "    \n",
    "    # 1) Get the test data for evaluation\n",
    "    # We use a fixed random_state in split function to ensure X_test matches clf training\n",
    "    _, X_test, _, y_test = train_test_split_table(df)\n",
    "    \n",
    "    # 2) Fit the model\n",
    "    clf = fit_linear_svm(df)\n",
    "\n",
    "    # 3) Define thresholds and sweep\n",
    "    thresholds = np.linspace(-2.0, 2.0, 21)\n",
    "    \n",
    "    # FIX: Ensure arguments match the definition: (y_true, thresholds, X, clf)\n",
    "    df_results = sweep_thresholds(\n",
    "        y_test,\n",
    "        thresholds,\n",
    "        X_test,\n",
    "        clf\n",
    "    )\n",
    "\n",
    "    print(\"Threshold sweep results (first 5 rows):\")\n",
    "    print(df_results)\n",
    "\n",
    "    # 4) Identify optimal threshold\n",
    "    best_row = df_results.loc[df_results[\"total_cost\"].idxmin()]\n",
    "    print(\"\\n--- Optimal Result ---\")\n",
    "    print(best_row)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f8baea",
   "metadata": {},
   "source": [
    "PROBLEM 3: Confidence estimation of the cost\n",
    "\n",
    "In Problem 2, you trained a classifier, selected a decision threshold, evaluated its performance on a test set, and computed the cost\n",
    "\n",
    "In this problem, you will quantify the uncertainty of this estimated cost. Each observation in the test set produces a cost depending on the\n",
    "classification outcome:\n",
    "\n",
    "    TN: 0\n",
    "   \n",
    "    FP: 100\n",
    "\n",
    "    TP: 0\n",
    "\n",
    "    FN: 500\n",
    "\n",
    "Thus, the cost per observation is a bounded random variable taking\n",
    "values in the interval [0, 500].\n",
    "\n",
    "Tasks:\n",
    "1. Compute the average cost per observation on the test set.\n",
    "2. Use Hoeffdingâ€™s inequality to construct a 95% confidence interval\n",
    "   for the true expected cost of the classifier.\n",
    "3. Interpret the resulting interval:\n",
    "   - What does it say about the reliability of your estimate?\n",
    "   - Is the interval likely to be tight or conservative? Why?\n",
    "\n",
    "You may assume that test observations are independent and identically\n",
    "distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfb275e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Cost Analysis (Threshold: 0.0) ---\n",
      "Mean Cost per Observation: $14.00\n",
      "95% Hoeffding CI: [$-13.72, $41.72]\n",
      "Sample Size (n): 600\n"
     ]
    }
   ],
   "source": [
    "def per_observation_cost(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Compute a vector where each element is the cost of a single prediction.\n",
    "    \"\"\"\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    costs_vector = np.zeros_like(y_true, dtype=float)\n",
    "\n",
    "    # Assign costs based on outcomes\n",
    "    # FN: True=1, Pred=0 -> 500\n",
    "    costs_vector[(y_true == 1) & (y_pred == 0)] = 500\n",
    "    # FP: True=0, Pred=1 -> 100\n",
    "    costs_vector[(y_true == 0) & (y_pred == 1)] = 100\n",
    "    # TP and TN are 0, so no need to explicitly set them\n",
    "    \n",
    "    return costs_vector\n",
    "\n",
    "def hoeffding_ci(per_obs_costs, delta=0.05):\n",
    "    \"\"\"\n",
    "    Computes the 1-delta confidence interval for the mean cost.\n",
    "    \"\"\"\n",
    "    n = len(per_obs_costs)\n",
    "    mean_cost = np.mean(per_obs_costs)\n",
    "    \n",
    "    # Range of the random variable [a, b]\n",
    "    a = 0\n",
    "    b = 500\n",
    "    range_sq = (b - a)**2\n",
    "\n",
    "    # Compute epsilon (the margin of error)\n",
    "    epsilon = np.sqrt((range_sq * np.log(2 / delta)) / (2 * n))\n",
    "\n",
    "    ci_lower = mean_cost - epsilon\n",
    "    ci_upper = mean_cost + epsilon\n",
    "    \n",
    "    return mean_cost, (ci_lower, ci_upper)\n",
    "\n",
    "def main():\n",
    "    # 1) Setup data and model\n",
    "    df = generate_fraud_table()\n",
    "    _, X_test, _, y_test = train_test_split_table(df)\n",
    "    clf = fit_linear_svm(df)\n",
    "\n",
    "    # 2) Define a threshold and get predictions\n",
    "    # Let's use 0.0 (default) or the best one from your sweep\n",
    "    target_threshold = 0.0 \n",
    "    y_scores = clf.decision_function(X_test)\n",
    "    y_pred = (y_scores >= target_threshold).astype(int)\n",
    "\n",
    "    # 3) Compute per-observation costs\n",
    "    costs_vec = per_observation_cost(y_test, y_pred)\n",
    "\n",
    "    # 4) Calculate Hoeffding Confidence Interval\n",
    "    mean_val, interval = hoeffding_ci(costs_vec, delta=0.05)\n",
    "\n",
    "    # This is correct but the cost cant be negative so clip it to 0\n",
    "\n",
    "    print(f\"--- Cost Analysis (Threshold: {target_threshold}) ---\")\n",
    "    print(f\"Mean Cost per Observation: ${mean_val:.2f}\")\n",
    "    print(f\"95% Hoeffding CI: [${interval[0]:.2f}, ${interval[1]:.2f}]\")\n",
    "    print(f\"Sample Size (n): {len(y_test)}\")\n",
    "\n",
    "main()\n",
    "\n",
    "\n",
    "# Discussion:\n",
    "\n",
    "# Tightness (Conservative Nature):\n",
    "# The interval is very conservative (wide).Reason 1:\n",
    "# It only considers the range ($0$ to $500$). It doesn't care if $99\\%$ of your costs are actually $\\$0$.\n",
    "# It assumes the worst-case variance.\n",
    "# \n",
    "# Reason 2: It ignores the actual variance of your sample.\n",
    "# If you used a Central Limit Theorem (CLT) based approach (like a T-distribution),\n",
    "# your interval would likely be much tighter because your actual standard deviation is probably much smaller than the theoretical maximum of $250$."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

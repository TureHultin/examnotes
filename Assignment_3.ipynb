{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3773e0e",
   "metadata": {
    "deletable": false
   },
   "source": [
    "\n",
    "# Assignment 3 for Course 1MS041\n",
    "Make sure you pass the `# ... Test` cells and\n",
    " submit your solution notebook in the corresponding assignment on the course website. You can submit multiple times before the deadline and your highest score will be used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa588f57",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "3",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "8"
   },
   "source": [
    "---\n",
    "## Assignment 3, PROBLEM 1\n",
    "Maximum Points = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea37109a",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "3",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "8"
   },
   "source": [
    "\n",
    "Download the updated data folder from the course github website or just download directly the file [https://github.com/datascience-intro/1MS041-2025/blob/main/notebooks/data/smhi.csv](https://github.com/datascience-intro/1MS041-2025/blob/main/notebooks/data/smhi.csv) from the github website and put it inside your data folder, i.e. you want the path `data/smhi.csv`. The data was aquired from SMHI (Swedish Meteorological and Hydrological Institute) and constitutes per hour measurements of wind in the Uppsala Aut station. The data consists of windspeed and direction. Your goal is to load the data and work with it a bit. The code you produce should load the file as it is, please do not alter the file as the autograder will only have access to the original file.\n",
    "\n",
    "The file information is in Swedish so you need to use some translation service, for instance `Google translate` or ChatGPT.\n",
    "\n",
    "1. [2p] Load the file, for instance using the `csv` package. Put the wind-direction as a numpy array and the wind-speed as another numpy array.\n",
    "2. [2p] Use the wind-direction (see [Wikipedia](https://en.wikipedia.org/wiki/Wind_direction)) which is an angle in degrees and convert it into a point on the unit circle **which is the direction the wind is blowing to** (compare to definition of radians [Wikipedia](https://en.wikipedia.org/wiki/Radian)). Store the `x_coordinate` as one array and the `y_coordinate` as another. From these coordinates, construct the wind-velocity vector.\n",
    "3. [2p] Calculate the average wind velocity and convert it back to direction and compare it to just taking average of the wind direction as given in the data-file.\n",
    "4. [2p] The wind velocity is a $2$-dimensional random variable, calculate the empirical covariance matrix which should be a numpy array of shape (2,2).\n",
    "\n",
    "For you to wonder about, is it more likely for you to have headwind or not when going to the university in the morning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "1d555ce1",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "3",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "8"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import math\n",
    "\n",
    "# --- Part 1: Data Loading and Array Creation ---\n",
    "winds_dir = []\n",
    "winds_speed = []\n",
    "\n",
    "filepath = \"data/smhi.csv\"\n",
    "\n",
    "# Use ISO-8859-1 encoding and semicolon delimiter\n",
    "with open(filepath, encoding=\"ISO-8859-1\") as f: \n",
    "    reader = csv.reader(f, delimiter=';')\n",
    "\n",
    "    # Skip 12 metadata/header rows\n",
    "    for _ in range(12):\n",
    "        next(reader) \n",
    "\n",
    "    for row in reader:\n",
    "        # Data columns: Date(0), Time(1), Direction(2), Quality(3), Speed(4)\n",
    "        if len(row) > 4:\n",
    "            try:\n",
    "                # Column 3 (index 2) = Wind Direction\n",
    "                wind_dir_str = row[2].strip()\n",
    "                # Column 5 (index 4) = Wind Speed\n",
    "                wind_speed_str = row[4].strip()\n",
    "                \n",
    "                if wind_dir_str and wind_speed_str and wind_dir_str != '999': # Check for non-empty and non-missing codes\n",
    "                    wind_dir_value = float(wind_dir_str)\n",
    "                    wind_speed_value = float(wind_speed_str)\n",
    "                    \n",
    "                    if 0 <= wind_dir_value <= 360 and wind_speed_value >= 0:\n",
    "                        winds_dir.append(wind_dir_value)\n",
    "                        winds_speed.append(wind_speed_value)\n",
    "                        \n",
    "            except (ValueError, IndexError):\n",
    "                continue\n",
    "\n",
    "problem1_wind_direction = np.array(winds_dir, dtype=np.float64)\n",
    "problem1_wind_speed = np.array(winds_speed, dtype=np.float64)\n",
    "\n",
    "\n",
    "# --- Part 2: Velocity Vector Construction ---\n",
    "\n",
    "# 1. Convert Meteo FROM direction to Meteo TO direction (180 degrees difference)\n",
    "wind_blows_to_degrees = (problem1_wind_direction + 180) % 360\n",
    "\n",
    "# 2. Convert Meteo TO angle to Standard Math angle (0=East, counter-clockwise)\n",
    "degrees_to_math = 90 - wind_blows_to_degrees\n",
    "radians_to_math = np.radians(degrees_to_math)\n",
    "\n",
    "# 3. Calculate unit vector coordinates (x=cos, y=sin)\n",
    "problem1_wind_direction_x_coordinate = np.cos(radians_to_math)\n",
    "problem1_wind_direction_y_coordinate = np.sin(radians_to_math)\n",
    "\n",
    "# 4. Construct velocity vector (Magnitude * Unit Vector)\n",
    "problem1_wind_velocity_x_coordinate = problem1_wind_direction_x_coordinate * problem1_wind_speed\n",
    "problem1_wind_velocity_y_coordinate = problem1_wind_direction_y_coordinate * problem1_wind_speed\n",
    "\n",
    "\n",
    "# --- Part 3: Average Velocity and Direction Comparison ---\n",
    "\n",
    "# Put the average wind velocity x and y coordinates here in these variables\n",
    "problem1_average_wind_velocity_x_coordinate = np.mean(problem1_wind_velocity_x_coordinate)\n",
    "problem1_average_wind_velocity_y_coordinate = np.mean(problem1_wind_velocity_y_coordinate)\n",
    "\n",
    "# 1. Average Wind Velocity Vector Angle (The correct average direction, converted back to Meteo TO)\n",
    "avg_radians_math = np.arctan2(problem1_average_wind_velocity_y_coordinate, problem1_average_wind_velocity_x_coordinate)\n",
    "avg_degrees_math = np.degrees(avg_radians_math) % 360 \n",
    "problem1_average_wind_velocity_angle_degrees = (90 - avg_degrees_math) % 360\n",
    "\n",
    "# 2. Simple Average of Wind Direction (The mathematically flawed angle average)\n",
    "problem1_average_wind_direction_angle_degrees = np.mean(problem1_wind_direction)\n",
    "\n",
    "# Finally, are they the same?\n",
    "problem1_same_angle = np.isclose(problem1_average_wind_velocity_angle_degrees, problem1_average_wind_direction_angle_degrees)\n",
    "\n",
    "\n",
    "# --- Part 4: Covariance Matrix ---\n",
    "\n",
    "# Stack x and y velocity components as rows\n",
    "velocity_data = np.stack(\n",
    "    (problem1_wind_velocity_x_coordinate, problem1_wind_velocity_y_coordinate),\n",
    "    axis=0\n",
    ")\n",
    "\n",
    "# Calculate the empirical covariance matrix. \n",
    "problem1_wind_velocity_covariance_matrix = np.cov(velocity_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "2a021927",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "3",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "8"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "# 1. Calculate the direction the wind blows TO (180 degrees opposite FROM)\n",
    "wind_blows_to_degrees = (problem1_wind_direction + 180) % 360\n",
    "\n",
    "# 2. Convert to standard mathematical angle convention (0=East, counter-clockwise)\n",
    "# Math_Angle = 90 - Meteo_Angle_TO\n",
    "degrees_to_math = 90 - wind_blows_to_degrees\n",
    "radians_to_math = np.radians(degrees_to_math)\n",
    "\n",
    "# 3. Calculate unit vector coordinates (x=cos, y=sin)\n",
    "problem1_wind_direction_x_coordinate = np.cos(radians_to_math)\n",
    "problem1_wind_direction_y_coordinate = np.sin(radians_to_math)\n",
    "\n",
    "# 4. Construct velocity vector (Magnitude * Unit Vector)\n",
    "problem1_wind_velocity_x_coordinate = problem1_wind_direction_x_coordinate * problem1_wind_speed\n",
    "problem1_wind_velocity_y_coordinate = problem1_wind_direction_y_coordinate * problem1_wind_speed\n",
    "\n",
    "# print(\"Wind Velocity X Coordinate:\", problem1_wind_velocity_x_coordinate) # Too large to print\n",
    "# print(\"Wind Velocity Y Coordinate:\", problem1_wind_velocity_y_coordinate) # Too large to print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "e5eaa4a4",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "3",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Wind Velocity Angle (degrees): 20.12646997879915\n",
      "Average Wind Direction Angle (degrees): 192.281280627246\n"
     ]
    }
   ],
   "source": [
    "# Put the average wind velocity x and y coordinates here in these variables\n",
    "problem1_average_wind_velocity_x_coordinate = np.mean(problem1_wind_velocity_x_coordinate)\n",
    "problem1_average_wind_velocity_y_coordinate = np.mean(problem1_wind_velocity_y_coordinate)\n",
    "\n",
    "# --- 1. Average Wind Velocity Vector Angle (The correct average direction) ---\n",
    "# a. Get angle in standard math radians (-pi to pi) from the mean vector\n",
    "avg_radians_math = np.arctan2(problem1_average_wind_velocity_y_coordinate, problem1_average_wind_velocity_x_coordinate)\n",
    "# b. Convert to degrees (0 to 360)\n",
    "avg_degrees_math = np.degrees(avg_radians_math) % 360 \n",
    "# c. Convert back to meteorological 'wind blowing TO' (0=N, clockwise)\n",
    "problem1_average_wind_velocity_angle_degrees = (90 - avg_degrees_math) % 360\n",
    "\n",
    "# --- 2. Simple Average of Wind Direction (The wrong average direction) ---\n",
    "# The simple mean of angles is mathematically flawed for circular data (e.g., 1 degree and 359 degrees average to 180, not 0)\n",
    "problem1_average_wind_direction_angle_degrees = np.mean(problem1_wind_direction)\n",
    "\n",
    "print(\"Average Wind Velocity Angle (degrees):\", problem1_average_wind_velocity_angle_degrees)\n",
    "print(\"Average Wind Direction Angle (degrees):\", problem1_average_wind_direction_angle_degrees)\n",
    "\n",
    "# Finally, are they the same? (They should be different unless the wind is highly concentrated)\n",
    "problem1_same_angle = np.isclose(problem1_average_wind_velocity_angle_degrees, problem1_average_wind_direction_angle_degrees)\n",
    "# If np.isclose is not allowed, use: abs(A - B) < tolerance\n",
    "# problem1_same_angle = abs(problem1_average_wind_velocity_angle_degrees - problem1_average_wind_direction_angle_degrees) < 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "30621c34",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "3",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "8"
   },
   "outputs": [],
   "source": [
    "# Stack the x and y coordinates of the wind velocity vector. \n",
    "# Rows will be the variables (vx, vy), columns will be the observations.\n",
    "velocity_data = np.stack(\n",
    "    (problem1_wind_velocity_x_coordinate, problem1_wind_velocity_y_coordinate),\n",
    "    axis=0\n",
    ")\n",
    "\n",
    "# Calculate the empirical covariance matrix. \n",
    "# np.cov assumes variables are rows by default if no axis is specified.\n",
    "problem1_wind_velocity_covariance_matrix = np.cov(velocity_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36b3462",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "3",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "8"
   },
   "source": [
    "---\n",
    "## Assignment 3, PROBLEM 2\n",
    "Maximum Points = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45238a00",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "3",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "8"
   },
   "source": [
    "\n",
    "For this problem you will need the [pandas](https://pandas.pydata.org/) package and the [sklearn](https://scikit-learn.org/stable/) package. Inside the `data` folder from the course website you will find a file called `indoor_train.csv`, this file includes a bunch of positions in (X,Y,Z) and also a location number. The idea is to assign a room number (Location) to the coordinates (X,Y,Z).\n",
    "\n",
    "1. [2p] Take the data in the file `indoor_train.csv` and load it using pandas into a dataframe `df_train`\n",
    "2. [3p] From this dataframe `df_train`, create two numpy arrays, one `Xtrain` and `Ytrain`, they should have sizes `(1154,3)` and `(1154,)` respectively. Their `dtype` should be `float64` and `int64` respectively.\n",
    "3. [3p] Train a Support Vector Classifier, `sklearn.svc.SVC`, on `Xtrain, Ytrain` with `kernel='linear'` and name the trained model `svc_train`.\n",
    "\n",
    "To mimic how [kaggle](https://www.kaggle.com/) works, the Autograder has access to a hidden test-set and will test your fitted model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "a13a0482",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "3",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "8"
   },
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "df_train = pd.read_csv(\"data/indoor_train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d297b4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "da145026",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "3",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xtrain: (1154, 3)\n",
      "Ytrain: (1154,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Xtrain = np.array(df_train.drop(columns=[\"Location\"]).astype(float))\n",
    "Ytrain = np.array(df_train[\"Location\"].astype(int))\n",
    "\n",
    "print(\"Xtrain:\", Xtrain.shape)\n",
    "print(\"Ytrain:\", Ytrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "c0663333",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "3",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "8"
   },
   "outputs": [],
   "source": [
    "\n",
    "svc_train = SVC(kernel='linear').fit(Xtrain, Ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc8d473",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "3",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "8"
   },
   "source": [
    "---\n",
    "## Assignment 3, PROBLEM 3\n",
    "Maximum Points = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec7f987",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "3",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "8"
   },
   "source": [
    "\n",
    "Let us build a proportional model ($\\mathbb{P}(Y=1 \\mid X) = G(\\beta_0+\\beta \\cdot X)$ where $G$ is the logistic function) for the spam vs not spam data. Here we assume that the features are presence vs not presence of a word, let $X_1,X_2,X_3$ denote the presence (1) or absence (0) of the words $(\"free\", \"prize\", \"win\")$.\n",
    "\n",
    "1. [2p] Load the file `data/spam.csv` and create two numpy arrays, `problem3_X` which has shape **(n_texts,3)** where each feature in `problem3_X` corresponds to $X_1,X_2,X_3$ from above, `problem3_Y` which has shape **(n_texts,)** and consists of a $1$ if the email is spam and $0$ if it is not. Split this data into a train-calibration-test sets where we have the split $40\\%$, $20\\%$, $40\\%$, put this data in the designated variables in the code cell.\n",
    "\n",
    "2. [2p] Follow the calculation from the lecture notes where we derive the logistic regression and implement the final loss function inside the class `ProportionalSpam`. You can use the `Test` cell to check that it gives the correct value for a test-point.\n",
    "\n",
    "3. [2p] Train the model `problem3_ps` on the training data. The goal is to calibrate the probabilities output from the model. Start by creating a new variable `problem3_X_pred` (shape `(n_samples,1)`) which consists of the predictions of `problem3_ps` on the calibration dataset. Then train a calibration model using `sklearn.tree.DecisionTreeRegressor`, store this trained model in `problem3_calibrator`. Recall that calibration error is the following for a fixed function $f$\n",
    "$$\n",
    "    \\sqrt{\\mathbb{E}[|\\mathbb{E}[Y \\mid f(X)] - f(X)|^2]}.\n",
    "$$\n",
    "\n",
    "4. [2p] Use the trained model `problem3_ps` and the calibrator `problem3_calibrator` to make final predictions on the testing data, store the prediction in `problem3_final_predictions`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "5f0bc703",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "3",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2229, 3) (1114, 3) (2229, 3) (2229,) (1114,) (2229,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = pd.read_csv('data/spam.csv', encoding='latin-1')\n",
    "X1 = \"free\"\n",
    "X2 = \"prize\"\n",
    "X3 = \"win\"\n",
    "\n",
    "feature_list = []\n",
    "target_list = []\n",
    "\n",
    "for text, spam_label in zip(data['v2'], data['v1']):\n",
    "\n",
    "    feature_row_bools = [X1 in text, X2 in text, X3 in text]\n",
    "    feature_list.append(feature_row_bools)\n",
    "\n",
    "    target_value = (spam_label == 'spam') # True/False\n",
    "    target_list.append(target_value)\n",
    "\n",
    "problem3_X = np.array(feature_list).astype(int)\n",
    "problem3_Y = np.array(target_list).astype(int)\n",
    "\n",
    "problem3_X_calib, X_temp, problem3_Y_calib, Y_temp = train_test_split(\n",
    "    problem3_X, problem3_Y, test_size=0.8, random_state=42\n",
    ")\n",
    "problem3_X_train, problem3_X_test, problem3_Y_train, problem3_Y_test = train_test_split(\n",
    "    X_temp, Y_temp, test_size=0.5, random_state=42\n",
    ")\n",
    "\n",
    "print(problem3_X_train.shape,problem3_X_calib.shape,problem3_X_test.shape,problem3_Y_train.shape,problem3_Y_calib.shape,problem3_Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "522b4096",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "3",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "8"
   },
   "outputs": [],
   "source": [
    "class ProportionalSpam(object):\n",
    "    def __init__(self):\n",
    "        self.coeffs = None\n",
    "        self.result = None\n",
    "    \n",
    "    # Helper function to add the intercept column\n",
    "    def _augment_X(self, X):\n",
    "        import numpy as np\n",
    "        ones = np.ones((X.shape[0], 1))\n",
    "        # X is (N, D), returns X_aug (N, D+1)\n",
    "        return np.hstack([ones, X])\n",
    "\n",
    "    # 1. FIX: loss method augments X internally\n",
    "    def loss(self, X, Y, coeffs):\n",
    "        import numpy as np\n",
    "        \n",
    "        # Augment X to match the size of coeffs (3 features + 1 intercept = 4)\n",
    "        X_aug = self._augment_X(X)\n",
    "        \n",
    "        # The dot product now works: (N, 4) @ (4,) -> (N,)\n",
    "        Z = X_aug @ coeffs \n",
    "        Y_hat = 1 / (1 + np.exp(-Z))\n",
    "        epsilon = 1e-15\n",
    "        \n",
    "        # This is the negative log-likelihood loss for logistic regression\n",
    "        loss_value = -np.mean(Y * np.log(Y_hat + epsilon) + (1 - Y) * np.log(1 - Y_hat + epsilon))\n",
    "        return loss_value\n",
    "\n",
    "    def fit(self, X, Y):\n",
    "        import numpy as np\n",
    "        from scipy import optimize\n",
    "\n",
    "        # We pass the non-augmented X to the optimizer, which in turn calls loss(X, Y, coeffs)\n",
    "        # where the augmentation happens.\n",
    "        opt_loss = lambda coeffs: self.loss(X, Y, coeffs)\n",
    "        \n",
    "        # The optimizer needs an initial guess for the D+1 coefficients.\n",
    "        initial_arguments = np.zeros(shape=X.shape[1] + 1) \n",
    "        \n",
    "        self.result = optimize.minimize(opt_loss, initial_arguments, method='cg')\n",
    "        self.coeffs = self.result.x\n",
    "    \n",
    "    # 2. FIX: predict method augments X internally\n",
    "    def predict(self, X):\n",
    "        import numpy as np\n",
    "        if (self.coeffs is not None):\n",
    "            # Augment X for prediction\n",
    "            X_aug = self._augment_X(X)\n",
    "            \n",
    "            # G = sigmoid function\n",
    "            G = lambda z: np.exp(z) / (1 + np.exp(z))\n",
    "            \n",
    "            # Z = X_aug @ self.coeffs\n",
    "            Z = X_aug @ self.coeffs \n",
    "\n",
    "            # Return the rounded probability\n",
    "            return np.round(10 * G(Z)) / 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "b97f059a",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "3",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "8"
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "ones_train = np.ones((problem3_X_train.shape[0], 1))\n",
    "problem3_X_train_aug = np.hstack([ones_train, problem3_X_train])\n",
    "\n",
    "problem3_ps = ProportionalSpam()\n",
    "problem3_ps.fit(problem3_X_train, problem3_Y_train)\n",
    "\n",
    "problem3_X_pred = problem3_ps.predict(problem3_X_calib)\n",
    "problem3_X_pred = problem3_X_pred.reshape(-1, 1)\n",
    "\n",
    "problem3_calibrator = DecisionTreeRegressor()\n",
    "problem3_calibrator.fit(problem3_X_pred, problem3_Y_calib)\n",
    "\n",
    "raw_calib_predictions = problem3_ps.predict(problem3_X_calib)\n",
    "\n",
    "problem3_X_pred = raw_calib_predictions.reshape(-1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "07f477aa",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "3",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "8"
   },
   "outputs": [],
   "source": [
    "\n",
    "problem3_final_predictions = problem3_calibrator.predict(\n",
    "    problem3_ps.predict(problem3_X_test).reshape(-1, 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5caed920",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "3",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "Test",
    "lx_problem_number": "3",
    "lx_problem_points": "8"
   },
   "source": [
    "---\n",
    "#### Local Test for Assignment 3, PROBLEM 3\n",
    "Evaluate cell below to make sure your answer is valid.                             You **should not** modify anything in the cell below when evaluating it to do a local test of                             your solution.\n",
    "You may need to include and evaluate code snippets from lecture notebooks in cells above to make the local test work correctly sometimes (see error messages for clues). This is meant to help you become efficient at recalling materials covered in lectures that relate to this problem. Such local tests will generally not be available in the exam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "1abcb445",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "3",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "Test",
    "lx_problem_number": "3",
    "lx_problem_points": "8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your loss was correct for a test point\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import numpy as np\n",
    "    test_instance = ProportionalSpam()\n",
    "    test_loss = test_instance.loss(np.array([[1,0,1],[0,1,1]]),np.array([1,0]),np.array([1.2,0.4,0.3,0.9]))\n",
    "    assert (np.abs(test_loss-1.2828629432232497) < 1e-6)\n",
    "    print(\"Your loss was correct for a test point\")\n",
    "except:\n",
    "    print(\"Your loss was not correct on a test point\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "lx_assignment_number": 3,
  "lx_course_instance": "2025",
  "lx_course_name": "Introduction to Data Science",
  "lx_course_number": "1MS041"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
